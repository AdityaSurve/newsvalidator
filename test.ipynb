{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"articles\": [\n",
    "        {\n",
    "            \"title\": \"Prime Minister inaugurates the $400 temple in Kanpur\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"President launches new initiative\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_main_verb(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    main_verb = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\" and token.dep_ != \"aux\":\n",
    "            main_verb = token.text\n",
    "            break\n",
    "    return main_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Prime Minister inaugurates the $400 temple in Kanpur to the data model\n",
      "Added President launches new initiative to the data model\n"
     ]
    }
   ],
   "source": [
    "from DataModelling import DataModel\n",
    "\n",
    "data_model = DataModel()\n",
    "\n",
    "\n",
    "for article in response[\"articles\"]:\n",
    "    title = article[\"title\"]\n",
    "    main_verb = get_main_verb(title)\n",
    "    custom_pattern = re.compile(fr'(?P<entity1>.+?)\\s+(?P<relation>\\b(?:{main_verb})\\b)\\s+(?P<entity2>.+)')\n",
    "    match = custom_pattern.match(title)\n",
    "    entity1 = match.group(\"entity1\").strip()\n",
    "    entity2 = match.group(\"entity2\").strip()\n",
    "    relation = match.group(\"relation\").strip()\n",
    "    data_model.add_entity(entity1)\n",
    "    data_model.add_entity(entity2)\n",
    "    data_model.add_relation(relation, [\n",
    "        entity1,\n",
    "        entity2\n",
    "    ])\n",
    "    data_model.save_to_csv()\n",
    "    print(f\"Added {entity1} {relation} {entity2} to the data model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "data = pd.read_csv(\"Relations.csv\")\n",
    "\n",
    "data['Entity1'] = data['Entity1'].astype(str)\n",
    "data['Entity2'] = data['Entity2'].astype(str)\n",
    "data['Relation'] = data['Relation'].astype(str)\n",
    "data['Entity1'] = data['Entity1'].str.lower()\n",
    "data['Entity2'] = data['Entity2'].str.lower()\n",
    "data['Relation'] = data['Relation'].str.lower()\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if \":\" in row['Entity1']:\n",
    "        data.at[index, 'Entity1'] = row['Entity1'].split(\":\")[1]\n",
    "    if \":\" in row['Entity2']:\n",
    "        data.at[index, 'Entity2'] = row['Entity2'].split(\":\")[1]\n",
    "\n",
    "\n",
    "unique_entities1 = pd.unique(data['Entity1'])\n",
    "unique_entities2 = pd.unique(data['Entity2'])\n",
    "\n",
    "for i in range(len(unique_entities1)):\n",
    "    for j in range(i+1, len(unique_entities1)):\n",
    "        entity1 = nlp(unique_entities1[i])\n",
    "        entity2 = nlp(unique_entities1[j])\n",
    "        similarity = entity1.similarity(entity2)\n",
    "        if similarity > 0.6:\n",
    "            data['Entity1'].replace(\n",
    "                unique_entities1[j], unique_entities1[i], inplace=True)\n",
    "\n",
    "for i in range(len(unique_entities2)):\n",
    "    for j in range(i+1, len(unique_entities2)):\n",
    "        entity1 = nlp(unique_entities2[i])\n",
    "        entity2 = nlp(unique_entities2[j])\n",
    "        similarity = entity1.similarity(entity2)\n",
    "        if similarity > 0.8:\n",
    "            data['Entity2'].replace(\n",
    "                unique_entities2[j], unique_entities2[i], inplace=True)\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.to_csv(\"Relations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "output_graphs/pm modi_relations.html\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "output_graphs/ corporate transparency act ruling_relations.html\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "output_graphs/navy officials_relations.html\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "output_graphs/ wwii ‘ghost army’_relations.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyvis.network import Network\n",
    "import os\n",
    "\n",
    "os.makedirs('output_graphs', exist_ok=True)\n",
    "\n",
    "data = pd.read_csv(\"Relations.csv\")\n",
    "\n",
    "unique_entities = pd.unique(data['Entity1'])\n",
    "\n",
    "for entity in unique_entities:\n",
    "    net = Network(notebook=True)\n",
    "    net.force_atlas_2based(spring_length=100)\n",
    "    entity_data = data[data['Entity1'] == entity]\n",
    "    relations = entity_data['Relation'].unique()\n",
    "\n",
    "    for relation in relations:\n",
    "        related_entities = entity_data[entity_data['Relation']\n",
    "                                       == relation]['Entity2'].tolist()\n",
    "\n",
    "        for related_entity in related_entities:\n",
    "            net.add_node(entity, color='skyblue', size=50, title=entity,\n",
    "                         label=entity, font={\"color\": \"black\", \"size\": 12})\n",
    "            net.add_node(related_entity, color='skyblue', size=50, title=related_entity,\n",
    "                         label=related_entity, font={\"color\": \"black\", \"size\": 12})\n",
    "            net.add_node(relation, color='red', size=50, title=relation,\n",
    "                         label=relation, font={\"color\": \"black\", \"size\": 12})\n",
    "            net.add_edge(entity, relation, )\n",
    "            net.add_edge(relation, related_entity)\n",
    "\n",
    "    net.show(f\"output_graphs/{entity}_relations.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Entity\n",
      "0                                             PM Modi\n",
      "1             Rs 8500 crore worth projects in Tripura\n",
      "2        Projects Worth Over Rs 4,500 Crore In Bengal\n",
      "3   projects worth Rs 55,600 crore in Northeast, i...\n",
      "4       Tax Breaks: Corporate Transparency Act Ruling\n",
      "5                    Attention As Tax Season Rolls On\n",
      "6                                      Navy Officials\n",
      "7   a Press Briefing on President Biden's Fiscal 2...\n",
      "8   125-ft tall statue of Lachit Barphukan at Holl...\n",
      "9   development projects of over Rs 4500 crore in ...\n",
      "10                       Prime Minister Narendra Modi\n",
      "11  125-feet tall statue of medieval-era Ahom gene...\n",
      "12     Rs 290 Crore Development Projects in the state\n",
      "13                                                 PM\n",
      "14     Rs 290 crore development projects in Meghalaya\n",
      "15                           WATCH: WWII ‘Ghost Army’\n",
      "16                      with Congressional Gold Medal\n",
      "17  WATCH: WWII ‘Ghost Army’ members, whose missio...\n",
      "18       with Congressional Gold Medal - PBS NewsHour\n",
      "19      After decades of secrecy, the 'Ghost Army' is\n",
      "20                      for saving U.S. lives in WWII\n",
      "21  WATCH LIVE: WWII Ghost Army, whose mission had...\n",
      "22  Word War Two ‘Ghost Army,’ Vital To D-Day Oper...\n",
      "23                          Congressional Gold Medals\n",
      "                                              Entity\n",
      "0                                            PM Modi\n",
      "1            Rs 8500 crore worth projects in Tripura\n",
      "2      Tax Breaks: Corporate Transparency Act Ruling\n",
      "3       Projects Worth Over Rs 4,500 Crore In Bengal\n",
      "4                                     Navy Officials\n",
      "5  125-ft tall statue of Lachit Barphukan at Holl...\n",
      "6                           WATCH: WWII ‘Ghost Army’\n",
      "7  a Press Briefing on President Biden's Fiscal 2...\n",
      "8                   Attention As Tax Season Rolls On\n",
      "9                      with Congressional Gold Medal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "data = pd.read_csv(\"Entities.csv\")\n",
    "print(data)\n",
    "unique_entities = pd.unique(data['Entity'])\n",
    "for i in range(len(unique_entities)):\n",
    "    for j in range(i+1, len(unique_entities)):\n",
    "        entity1 = nlp(unique_entities[i])\n",
    "        entity2 = nlp(unique_entities[j])\n",
    "        similarity = entity1.similarity(entity2)\n",
    "        if similarity > 0.6:\n",
    "            data['Entity'].replace(\n",
    "                unique_entities[j], unique_entities[i], inplace=True)\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "# data.to_csv(\"Entities.csv\", index=False)\n",
    "\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
