{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_name = input(\"What is the name of the player you want to search for? \")\n",
    "platform = input(\"What platform is the player on? \")\n",
    "type = input(\"What is the type of the player? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_player_name = player_name.replace(\" \", \"+\")\n",
    "processed_platform = platform.lower()\n",
    "processed_type = type.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "query = f\"https://www.bcci.tv/search?platform={processed_platform}&type={processed_type}&term={processed_player_name}&content_type=all\"\n",
    "\n",
    "if not processed_player_name or not processed_platform or not processed_type:\n",
    "    print(\"Invalid input\")\n",
    "    exit()\n",
    "else:\n",
    "    try:\n",
    "        response = requests.get(query)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    data = []\n",
    "\n",
    "    player_data = soup.find('div', class_='lv pc video-section-append-video-here')\n",
    "    if player_data:\n",
    "        player_card = player_data.find_all(\n",
    "            'div', class_='slick-card m-0 lv-bg hoverVideoPlayNow')\n",
    "        for card in player_card:\n",
    "            header_content = card.find('div', class_='bottom')\n",
    "            title_holder = None\n",
    "            title = \"\"\n",
    "            date = \"\"\n",
    "            views = \"\"\n",
    "            if header_content.find('div', class_='text-detail br-b'):\n",
    "                title_holder = header_content.find('div', class_='text-detail br-b')\n",
    "                date_holder = header_content.find('div', class_='text-detail br-b')\n",
    "                date =  date_holder.find('span').text\n",
    "                views_holder = header_content.find(\n",
    "                    'div', class_='tour-overlay-details')\n",
    "                list = views_holder.find('ul')\n",
    "                views = list.find_all('li')[0]\n",
    "                views = views.find('span', class_=\"me-3\").text\n",
    "                views = views.replace(\"&nbsp;\", \"\").replace(\n",
    "                    \"views\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0\", \"\").strip()\n",
    "                if \"k\" in views:\n",
    "                    views = views.replace(\"k\", \"\")\n",
    "                    views = float(views) * 1000\n",
    "                elif \"m\" in views:\n",
    "                    views = views.replace(\"m\", \"\")\n",
    "                    views = float(views) * 1000000\n",
    "            elif header_content.find('div', class_='text-detail pb-0'):\n",
    "                title_holder = header_content.find('div', class_='text-detail pb-0')\n",
    "                date_holder = header_content.find(\n",
    "                    'div', class_='tour-overlay-details')\n",
    "                ul = date_holder.find('ul')\n",
    "                date_ = ul.find_all('li')[0]\n",
    "                date = date_.find('span').text\n",
    "                views = \"-\"\n",
    "            if title_holder:\n",
    "                title = title_holder.find('p').text\n",
    "\n",
    "            data.append({\n",
    "                \"title\": title,\n",
    "                \"date\": date,\n",
    "                \"views\": views,\n",
    "                \"platform\": processed_platform,\n",
    "                \"type\": processed_type,\n",
    "                \"player_name\": player_name,\n",
    "                \"sport\": \"Cricket\"\n",
    "            })\n",
    "        if data:\n",
    "            df = pd.DataFrame(data)\n",
    "            header = ['title', 'date', 'views', 'platform', 'type', 'player_name']\n",
    "            if os.path.isfile('Sports.csv') and os.path.getsize('Sports.csv') > 0:\n",
    "                df.to_csv('Sports.csv', mode='a', header=False, index=False)\n",
    "            else:\n",
    "                df.to_csv('Sports.csv', mode='a', header=header, index=False)\n",
    "    else:\n",
    "        print(\"Player not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ICC_Scrapper:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://www.icc-cricket.com/search?\"\n",
    "        self.player_name = None\n",
    "\n",
    "    def get_player_data(self, player_name):\n",
    "        processed_player_name = player_name.replace(\" \", \"%20\")\n",
    "\n",
    "        if not processed_player_name:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.player_name = processed_player_name\n",
    "\n",
    "        url = self.url + \"q=\" + self.player_name\n",
    "\n",
    "        response = self.get_data(processed_player_name, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "\n",
    "    def get_data(self, player_name, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        player_data = soup.find(\n",
    "            'div', class_='my-4 grid grid-cols-1 lg:grid-cols-4 gap-6 lg:gap-x-6 lg:gap-y-10')\n",
    "        if player_data:\n",
    "            cards = player_data.find_all(\n",
    "                'div', class_='h-[541px] relative rounded-lg lg:rounded-[14px] overflow-hidden')\n",
    "            for card in cards:\n",
    "                title = \"\"\n",
    "                date = \"\"\n",
    "                content = \"\"\n",
    "                image_url = \"\"\n",
    "                link = \"\"\n",
    "                link_holder = card.find('a')\n",
    "                link = link_holder['href']\n",
    "                image_holder = link_holder.find_all(\n",
    "                    'div')[0]\n",
    "                image_holder = image_holder.find('picture')\n",
    "                image_holder = image_holder.find('img')\n",
    "                image_url = image_holder['src']\n",
    "                divs = link_holder.find_all('div')\n",
    "                if len(divs) > 1:\n",
    "                    content_holder = divs[1]\n",
    "                    content_holder = content_holder.find('div')\n",
    "                    title_holder = content_holder.find_all('div')[1] if len(\n",
    "                        content_holder.find_all('div')) > 1 else None\n",
    "                    if title_holder:\n",
    "                        title = title_holder.text\n",
    "                    content_holder = content_holder.find(\n",
    "                        'div', class_='text-sm font-bold text-white leading-[1.2] lg:text-lg lg:leading-[1.4] lg:-tracking-[0.72px]')\n",
    "                    if content_holder:\n",
    "                        content = content_holder.text\n",
    "                    date_holder = content_holder.find('time')\n",
    "                    date = date_holder.text if date_holder else \"\"\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                temp_player_name = player_name.replace(\"%20\", \" \")\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"date\": date,\n",
    "                    \"content\": content,\n",
    "                    \"player_name\": temp_player_name,\n",
    "                    \"image_url\": image_url,\n",
    "                    \"link\": link,\n",
    "                    \"sport\": \"Cricket\"\n",
    "                })\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'date', 'content',\n",
    "                          'player_name', 'image_url', 'link', 'sport']\n",
    "                if os.path.isfile('ICC.csv') and os.path.getsize('ICC.csv') > 0:\n",
    "                    df.to_csv('ICC.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('ICC.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = ICC_Scrapper()\n",
    "\n",
    "# player_name = \"MS Dhoni\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "player_name = \"Sachin Tendulkar\"\n",
    "scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Sourav Ganguly\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Ravindra Jadeja\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Jasprit Bumrah\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Mithali Raj\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Smriti Mandhana\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Jhulan Goswami\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Harmanpreet Kaur\"\n",
    "# scrapper.get_player_data(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class FIFA_Scrapper:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://www.fifa.com/en/search?\"\n",
    "        self.player_name = None\n",
    "\n",
    "    def get_player_data(self, player_name):\n",
    "        processed_player_name = player_name.replace(\" \", \"%20\")\n",
    "\n",
    "        if not processed_player_name:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.player_name = processed_player_name\n",
    "\n",
    "        url = self.url + \"q=\" + self.player_name\n",
    "\n",
    "        response = self.get_data(processed_player_name, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "\n",
    "    def get_data(self, player_name, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        player_data = soup.find(\n",
    "            'div', class_='search-results-page_searchResults__pKRI-')\n",
    "        if player_data:\n",
    "            title = \"\"\n",
    "            date = \"\"\n",
    "            content = \"\"\n",
    "            image_url = \"\"\n",
    "            link = \"\"\n",
    "            player_name = \"\"\n",
    "            sport = \"Football\"\n",
    "            cards = player_data.find_all('a')\n",
    "            for card in cards:\n",
    "                link = card['href']\n",
    "                date_holder = card.find(\n",
    "                    'div', class_='search-result-card_details__+1JIM')\n",
    "                date = date_holder.find('span')[1].text\n",
    "                image_holder = card.find(\n",
    "                    'div', class_='search-result-card_imageContainer__NgxbS')\n",
    "                image_holder = image_holder.find(\n",
    "                    'div', class_='image_imgContainer__nDjya')\n",
    "                image_holder = image_holder.find('img')\n",
    "                image_url = image_holder['src']\n",
    "                content_holder = card.find(\n",
    "                    'div', class_='search-result-card_textContainer__82BrL')\n",
    "                title_holder = content_holder.find(\n",
    "                    'div', class_='search-result-card_title__CTmi4')\n",
    "                title = title_holder.text\n",
    "                content_holder = content_holder.find(\n",
    "                    'div', class_='search-result-card_description__KiKIZ search-result-card_smallCardDescription__InIop')\n",
    "                content = content_holder.text\n",
    "                temp_player_name = player_name.replace(\"%20\", \" \")\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"date\": date,\n",
    "                    \"content\": content,\n",
    "                    \"player_name\": temp_player_name,\n",
    "                    \"image_url\": image_url,\n",
    "                    \"link\": link,\n",
    "                    \"sport\": sport\n",
    "                })\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'date', 'content',\n",
    "                          'player_name', 'image_url', 'link', 'sport']\n",
    "                if os.path.isfile('FIFA.csv') and os.path.getsize('FIFA.csv') > 0:\n",
    "                    df.to_csv('FIFA.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('FIFA.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = FIFA_Scrapper()\n",
    "\n",
    "player_name = \"Lionel Messi\"\n",
    "scrapper.get_player_data(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "class ICAR_Scrapper:\n",
    "    def __init__ (self):\n",
    "        self.url = \"https://www.icar.org.in/search/node?keys=\"\n",
    "        self.query = None\n",
    "\n",
    "    def get_query_data(self, query):\n",
    "        processed_query = query.replace(\" \", \"%20\")\n",
    "\n",
    "        if not processed_query:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.query = processed_query\n",
    "\n",
    "        url = self.url + processed_query\n",
    "\n",
    "        response = self.get_data(processed_query, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "        \n",
    "    def get_data(self, query, url):\n",
    "        try:\n",
    "            response = requests.get(url, verify=False)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        query_data = soup.find(\n",
    "            'ol', class_='search-results node_search-results')\n",
    "        if query_data:\n",
    "            title = \"\"\n",
    "            date = \"\"\n",
    "            content = \"\"\n",
    "            link = \"\"\n",
    "            place = \"\"\n",
    "\n",
    "            li_tags = query_data.find_all('li')\n",
    "            if li_tags:\n",
    "                for li in li_tags:\n",
    "                    title_holder = li.find('h3')\n",
    "                    title_holder = title_holder.find('a')\n",
    "                    link = title_holder['href']\n",
    "                    title = title_holder.text\n",
    "\n",
    "                    home_page = requests.get(link, verify=False)\n",
    "                    home_page.raise_for_status()\n",
    "                    home_soup = BeautifulSoup(home_page.text, 'html.parser')\n",
    "\n",
    "                    content_holder = home_soup.find(\n",
    "                        'div', class_='node__content clearfix')\n",
    "                    if content_holder:\n",
    "                        content_holder = content_holder.find(\n",
    "                            'div', class_='clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item')\n",
    "                    \n",
    "                    if content_holder:\n",
    "                        paragraphs = content_holder.find_all('p')\n",
    "                        if paragraphs[0].find('em'):\n",
    "                            date_place = paragraphs[0].find('em')\n",
    "                            date_place = date_place.text   \n",
    "                            date_place = date_place.split(',')\n",
    "                            if len(date_place) == 2:\n",
    "                                if any(char.isdigit() for char in date_place[0]):\n",
    "                                    date = date_place[0]\n",
    "                                    place = date_place[1]\n",
    "                                else:\n",
    "                                    date = date_place[1]\n",
    "                                    place = date_place[0]\n",
    "                            elif len(date_place) == 3:\n",
    "                                date = date_place[0] + ', ' + date_place[1]\n",
    "                                place = date_place[2]\n",
    "                            content = \"\"\n",
    "                            for i in range(1, len(paragraphs)):\n",
    "                                content += paragraphs[i].text + \" \"\n",
    "                        else:\n",
    "                            date = \"-\"\n",
    "                            place = \"-\"\n",
    "                            content = \"\"\n",
    "                            for i in range(0, len(paragraphs)):\n",
    "                                content += paragraphs[i].text + \" \"\n",
    "\n",
    "                    data.append({\n",
    "                        \"title\": title,\n",
    "                        \"date\": date,\n",
    "                        \"content\": content,\n",
    "                        \"link\": link,\n",
    "                        \"place\": place,\n",
    "                        \"query\": query,\n",
    "                        \"category\": \"Agriculture\"\n",
    "                    })\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'date', 'content', 'link', 'place', 'query', 'category']\n",
    "                if os.path.isfile('ICAR.csv') and os.path.getsize('ICAR.csv') > 0:\n",
    "                    df.to_csv('ICAR.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('ICAR.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Response': [{'title': 'Webinar on “Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”',\n",
       "   'date': '20th\\xa0August,  2020',\n",
       "   'content': 'The ICAR-National Research Centre on Grapes, Pune, Maharashtra organized a Webinar on\\xa0“Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”\\xa0today. In his address, Dr. Anand Kumar Singh, Deputy Director General (Horticultural Science), ICAR emphasized on the importance of following the good agricultural practices for pesticide applications in grape cultivation. Dr. Singh also urged the participants for providing the technologies and recommendations for effective management of pesticide residues in grapes. Shri Devendra Prasad, DGM, APEDA along with the members of Maharashtra State Grape Growers’ Association (MRDBS) also virtually participated in the Webinar. Earlier, in his welcome address, Dr. R.G. Somkuwar, Director, ICAR-NRC on Grapes, Pune, Maharashthra briefed about the current grape season. He accentuated on the updation of the list\\xa0list of agrochemicals in Annexure - 5 of the Residue Monitoring Plan Document based on the new CIB&RC-label claims for grapes by the Institute every year. Dr. Kaushik Banerjee, Incharge, NRL outlined the agenda and briefed about the structure of Annexure - 5 as the central theme of the pesticide residue control in the food safety traceability system, viz., Grapenet of APEDA. A total of 238 participants including the grape growers from the various locations of Maharashtra and Karnataka states virtually participated in the Webinar. (Source: ICAR-National Research Centre on Grapes, Pune, Maharashtra) ',\n",
       "   'link': 'https://www.icar.org.in/node/1206',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Webinar on “Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”',\n",
       "   'date': '20th\\xa0August,  2020',\n",
       "   'content': 'The ICAR-National Research Centre on Grapes, Pune, Maharashtra organized a Webinar on\\xa0“Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”\\xa0today. In his address, Dr. Anand Kumar Singh, Deputy Director General (Horticultural Science), ICAR emphasized on the importance of following the good agricultural practices for pesticide applications in grape cultivation. Dr. Singh also urged the participants for providing the technologies and recommendations for effective management of pesticide residues in grapes. Shri Devendra Prasad, DGM, APEDA along with the members of Maharashtra State Grape Growers’ Association (MRDBS) also virtually participated in the Webinar. Earlier, in his welcome address, Dr. R.G. Somkuwar, Director, ICAR-NRC on Grapes, Pune, Maharashthra briefed about the current grape season. He accentuated on the updation of the list\\xa0list of agrochemicals in Annexure - 5 of the Residue Monitoring Plan Document based on the new CIB&RC-label claims for grapes by the Institute every year. Dr. Kaushik Banerjee, Incharge, NRL outlined the agenda and briefed about the structure of Annexure - 5 as the central theme of the pesticide residue control in the food safety traceability system, viz., Grapenet of APEDA. A total of 238 participants including the grape growers from the various locations of Maharashtra and Karnataka states virtually participated in the Webinar. (Source: ICAR-National Research Centre on Grapes, Pune, Maharashtra) ',\n",
       "   'link': 'https://www.icar.org.in/node/12586',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': '20th Foundation Day of NRC for Grapes',\n",
       "   'date': ' 18th\\xa0January 2016.',\n",
       "   'content': 'Two progressive farmers Mr. Subash Arve (President MRDBS) and Mr Shivajirao Baste were felicitated for collaborating with NRC for Grapes in field of demonstration of technologies and varieties developed by the NRC for Grapes at the 20 Foundation Day of National Research Centre for Grapes. Mr Subash Arve delivered a\\xa0 technical talk on ‘ Current status of dry grape industry in India and its future’. \\xa0 The importance of keeping alive the interest of rural youth in agriculture for holistic development of the country and in tune with the market and consumer demands was emphasized by the chief guest Mr Dnyaneshwar Phadtare (Retd. Joint Commissioner of Vigilance, Maharashtra). Dr P. S. Minhas (Director, NIASM, Baramati) focused on the need to strengthen the collaborative work between NIASM and NRCG in the management of edaphic stress in grapes. Dr Jai Gopal (Director,DOGR) highlighted importance of breeding for development of grape varieties with desired traits. Dr K. V. Prasad (Director, DFR) spoke on the scope of incorporation of natural colors and flavors from ornamental crops in grape juice. The wall magazine,\\xa0‘Angoori’\\xa0 of NRC for Grapes brought out a special issue depicting photographs and memoirs of the establishment of the NRC for Grapes. (Source: ICAR-NRC on Grapes,\\xa0Pune) ',\n",
       "   'link': 'https://www.icar.org.in/node/4876',\n",
       "   'place': 'Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'NRC for Grapes, celebrates 120th Birth Anniversary of Dr. G.S. Cheema',\n",
       "   'date': 'August 2,  2014',\n",
       "   'content': '120th Birth Anniversary of Dr. G.S. Cheema was celebrated in National Research Centre for Grapes (NRCG), Pune.  Dr. S.D. Sawant, Director addressed the staff and highlighted Dr. Cheema’s contributions to horticulture especially in developing varieties namely Sardar Guava, Ganesh Pomegranate and Cheema Sahebi grapes. Dr. G.S. Cheema, an eminent horticulturist, who had been commonly referred to as the Father of Indian Horticulture. \\xa0 He also informed that the Centre has named its laboratory-cum-administrative building as Dr. G.S. Cheema Bhawan to recognize his contributions to grapes. (Source: NRC for Grapes, Pune) ',\n",
       "   'link': 'https://www.icar.org.in/node/9714',\n",
       "   'place': ' Pune ',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'ICAR-NRC for Grapes, organises National Conference on Generative AI',\n",
       "   'date': '11th-12th September 2023',\n",
       "   'content': \"ICAR-National Research Centre for Grapes, Pune, in collaboration with National Academy of Agricultural Sciences and Society for Advancement of Viticulture and Enology, held a two-day National Conference on “Generative AI in Practice for Empowering Agricultural Research Productivity” by virtual mode. \\xa0\\xa0 The Chief Guest of both Inauguration and Valedictory sessions, Dr. S. D. Sawant, former Vice Chancellor, Dr. Balasaheb Sawant Konkan Krishi Vidyapeeth, Dapoli, Ratnagiri emphasised on Generative AI's potential as a revolutionary tool in agricultural research. He mentioned that as we ventured into this new realm for reaping benefits, the emphasis remained on ethical deployment and responsible use. Dr. C.N. Ravishankar, Director, ICAR-CIFE, Mumbai, briefed them about potential applications of Generative AI in the aquaculture sector. Dr. Kaushik Banerjee, Director, ICAR-National Research Centre for Grapes, Pune and Convener, NAAS, emphasised on importance of learning and adopting generative AI for agricultural researchers for remaining relevant with fast changing technology. He also suggested to maintain balance with human intelligence. The online event drew 130 researchers from across the country over the course of two days. 30 lectures and six keynote addresses illuminated the broad potential of generative AI for the productivity of agricultural research. (Source: ICAR-National Research Centre for Grapes, Pune) \",\n",
       "   'link': 'https://www.icar.org.in/icar-nrc-grapes-organises-national-conference-generative-ai',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'National Research Centres',\n",
       "   'date': '-',\n",
       "   'content': 'Mahatma Gandhi Integrated Farming Research Institute ,Motihari ',\n",
       "   'link': 'https://www.icar.org.in/national-research-centres',\n",
       "   'place': '-',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Meeting of the Agmark Committee',\n",
       "   'date': '20th November 2023',\n",
       "   'content': 'ICAR-National Research Centre for Grapes, Pune hosted a meeting of the Agmark Committee Today, under the co-chairmanship of Dr. Kaushik Banerjee, Director, ICAR-NRCG, Pune and Shri. B.K. Tiwari, I/c Jt. AMA-DMI Faridabad.  The meeting was attended by Dr. Ashish Mukharjee, Director of Laboratories, Dr. Vijay Kumar Doharey Dy. Managing Director, National Horticulture Board, Dr. B.K. Joshi, Dy. AMA-RO, Mumbai, officials from DMI, APEDA, and the State Department of Agriculture, and representatives of grape growers and exporters. The agenda of the meeting was to discuss the quality parameters under a schedule of Grapes of Fruits and Vegetables, Grading and Marking Rules, 2004. To certify the early harvest grapes for export, it was decided to revise the sugar: acid ratio from the existing value of 20:1 to 18:1. This was unanimously accepted by all the stakeholders’ representatives, including Maharashtra State Grape Growers Association and the Grape Exporters Association of India. All the attendees felt that this change in the Agmark standard will substantially increase the export of grapes, especially in the early harvest season of January–February, when Achieving a sugar:acid ratio of 20:1 often appears challenging. (Source: ICAR-National Research Centre for Grapes, Pune) ',\n",
       "   'link': 'https://www.icar.org.in/meeting-agmark-committee',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Vision 2050',\n",
       "   'date': '-',\n",
       "   'content': 'Deemed Universities Institutions National Research Centres National Bureaux Directorates/Project Directorates ',\n",
       "   'link': 'https://www.icar.org.in/vision-2050',\n",
       "   'place': '-',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Agripreneurship Sensitization Programme',\n",
       "   'date': '5th March 2024',\n",
       "   'content': 'ICAR-National Research Centre for Grapes, Pune, ABI Draksha Centre, Pune organised an ‘Agripreneurship Sensitization Programme’ today for the students working under various projects of the institute. \\xa0\\xa0 Dr. Kaushik Banerjee, Director, ICAR-NRC for Grapes, highlighted the importance of science-based entrepreneurship developments in his address. He invited young minds to bring more and more innovations to enrich the agriculture-based business domain involving fresh grapes and processed products. A presentation on available opportunities and technologies developed by this research centre was also delivered during the programme. The programme was attended by more than 50 students. (Source: ICAR-National Research Centre for Grapes, Pune) ',\n",
       "   'link': 'https://www.icar.org.in/agripreneurship-sensitization-programme',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'ICAR Institutions, Deemed Universities, National Research Centres, National Bureaux, Directorate/Project Directorates & Agricultural Technology Application Research Institutes',\n",
       "   'date': '-',\n",
       "   'content': 'Mahatma Gandhi Integrated Farming Research Institute ,Motihari ',\n",
       "   'link': 'https://www.icar.org.in/institutes',\n",
       "   'place': '-',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper = ICAR_Scrapper()\n",
    "\n",
    "query = \"Grapes\"\n",
    "scraper.get_query_data(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class FAO_Scrapper:\n",
    "    def __init__ (self):\n",
    "        self.url = \"https://www.fao.org/home/search/en/?\"\n",
    "        self.query = None\n",
    "\n",
    "    def get_query_data(self, query):\n",
    "        processed_query = query.replace(\" \", \"+\")\n",
    "\n",
    "        if not processed_query:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.query = processed_query\n",
    "\n",
    "        url = self.url + \"q=\" + processed_query\n",
    "        response = self.get_data(processed_query, url)\n",
    "        \n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "        \n",
    "    def get_data(self, query, url):\n",
    "        try:\n",
    "            driver = webdriver.Edge()\n",
    "            driver.get(url)\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        query_data = soup.find('div', class_='gsc-expansionArea')\n",
    "        if query_data:\n",
    "            cards = query_data.find_all('div', class_='gsc-webResult gsc-result')\n",
    "            for card in cards:\n",
    "                title = \"\"\n",
    "                content = \"\"\n",
    "                description = \"\"\n",
    "                link = \"\"\n",
    "                category = \"Agriculture\"\n",
    "\n",
    "                card = card.find('div', class_='gs-webResult gs-result')\n",
    "                header = card.find('div', class_='gsc-thumbnail-inside')\n",
    "                title_holder = header.find('div', class_='gs-title')\n",
    "                a_tag = title_holder.find('a')\n",
    "                link = a_tag['href']\n",
    "                title = a_tag.text\n",
    "\n",
    "                home_driver = webdriver.Edge()\n",
    "                home_driver.get(link)\n",
    "                home_soup = BeautifulSoup(home_driver.page_source, 'html.parser')\n",
    "\n",
    "                content_holder = home_soup.find('section', id='content')\n",
    "                if content_holder:\n",
    "                    content_holder = content_holder.find(\n",
    "                        'div', class_='main-internal')\n",
    "                    if content_holder:\n",
    "                        desc_holder = content_holder.find(\n",
    "                            'div', class_='csc-default')\n",
    "                        if desc_holder:\n",
    "                            desc_holder = desc_holder.find('p', class_='bodytext')\n",
    "                            if desc_holder:\n",
    "                                description = desc_holder.text\n",
    "                            else :\n",
    "                                description = \"-\"\n",
    "                        \n",
    "                        content_holder = content_holder.find_all(\n",
    "                            'div', class_='rgaccord1-nest')\n",
    "                        if content_holder:\n",
    "                            content = \"\"\n",
    "                            for div in content_holder:\n",
    "                                section_title_holder = div.find('h3')\n",
    "                                section_title = section_title_holder.text\n",
    "\n",
    "                                text_holder = div.find('div')\n",
    "                                text_holder = text_holder.find('div')\n",
    "                                text = ''\n",
    "                                \n",
    "                                if text_holder:\n",
    "                                    text = text_holder.text\n",
    "                                \n",
    "\n",
    "                                content += section_title + \"\\n\" + text + \"\\n\\n\"\n",
    "\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"content\": content,\n",
    "                    \"description\": description,\n",
    "                    \"link\": link,\n",
    "                    \"query\": query,\n",
    "                    \"category\": category\n",
    "                })\n",
    "            home_driver.quit()\n",
    "            driver.quit()\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'content', 'description', 'link', 'query', 'category']\n",
    "                if os.path.isfile('FAO.csv') and os.path.getsize('FAO.csv') > 0:\n",
    "                    df.to_csv('FAO.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('FAO.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "            \n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Response': [{'title': 'Grape - Food and Agriculture Organization of the United Nations',\n",
       "   'content': 'Crop Description and Climate\\nCrop Description and ClimateGrape is believed to originate from the Caspian and Caucasian regions. Most cultivated vines belong to the European type (Vitis vinefera), the American bunch type (V. labrusca\\xa0and its derivatives) or Muscadine type (V. rotundifolia). The total production of grapes is about 61.95 million tons from 7.3 million ha. (FAOSTAT, 2001)\\n\\nGrape is grown between about 50°N and S, with suitable areas being small at these limits. The crop needs a long, warm to hot, dry summer and a cool winter. The subtropics with winter rain are most suited. Rain or cold and cloudy weather during flowering may adversely affect fruit setting whereas rain during ripening may lead to fruit rot. Where raisins are produced by sun-drying between the vine rows, at least one warm, sunny month without rain following harvest is essential.\\n\\nIn climates with a cool winter, the grape can survive temperatures down to -18°C, but once new growth begins, minor frost will kill the fruiting shoots. Rapid and succulent growth of shoots starts when mean daily temperatures reach l0°C. During flowering the rate of shoot growth declines and stops when the grapes are mature. The time from flowering to maturity can be expressed as the sum of mean daily temperature above 10°C or S(T - l0°C), which is about 900 degree-days for early varieties and 2000 for late varieties. Under cool to moderate warm weather, fruits ripen slowly and produce dry table wines of good quality. In warmer climates, the heat before and during ripening favours a high sugar content, which makes fruits better suited for port and sherry production. During and after harvest no new shoot growth should take place but leaves should be retained. In the autumn shoots, then also called canes, become woody and lose their leaves.\\n\\nIn the tropics (with less than 1 percent of the world production), the vine is an evergreen and can produce fresh fruits throughout the year. In general, two harvests of relatively poor quality and low yields are obtained annually with harvest dates controlled by adjusting the time of pruning.\\n\\nGrapes are adapted to a wide range of soils, except when poorly drained or when salt content is high. In general, light soils are preferred. High production can be obtained under rainfed conditions, but without summer rain a deep soil with a high water holding capacity is required. Under irrigation, grape can be grown success-fully on shallow soils of 0.6 m depth or less.\\n\\nOn deep, fertile soil, the largest vines and high yields are produced. On soils of low fertility or limited depth, yields are usually lower, but fruit quality can be better. Fertilizer requirements are 100 to 160 kg/ha N, 40 to 60 kg/ha P and 160 to 230 kg/ha K. The greatest amount of nitrogen is needed during early spring growth and during the flowering period. During ripening, the nitrogen level must be low to prevent continuous vegetative growth.\\n\\nGrape vines are moderately sensitive to soil salinity and yield decrease is 0% at ECe 1.5 mmhos/cm, 10% at 2.5, 25% at 4.1, 50% at 6.7 and 100% at 12 mmhos/cm.\\n\\nMost grape varieties are propagated by cuttings, grown in a nursery for one year to produce roots. Where root louse is a problem, grape is grafted on resistant root-stocks. An important (and expensive) operation is the training, pruning and staking of the vines and thinning of clusters. In the tropics the time of pruning determines the time of fruiting. The plant spacing is also influenced by the.pruning and training practices and can vary between 1.5 x 3.5 and 4.5 x 5.5 m.\\n\\nThe graph below depicts the crop stages of grape, and the table summarises the main crop coefficients used for water management.\\n\\n\\xa0\\n\\n\\n\\xa0Stages of DevelopmentPlant dateRegionCrop\\xa0characteristicInitialCrop\\xa0DevelopmentMid- seasonLateTotalGrapes-table or raisonStage length, days2020\\xa020304050506012075904060602080240205180210\\xa0AprilMarchMayApril\\xa0Low LatitudesCalif., USAHigh AltitudesMid Latitudes (wines)Depletion Coefficient, p----0.35\\xa0Root Depth, m1.5>>>>1.5\\xa0Crop Coefficient, Kc0.3>>0.850.45-\\xa0Yield Response Factor, Ky0.20.70.850.40.85\\xa0Grape-wineStage length, days2020\\xa02030405050120759040\\xa0 \\xa06060\\xa02080240205180210\\xa0AprilMarchMayApril\\xa0\\xa0Low LatitudesCalif., USAHigh AltitudesMid Latitudes (wines)Depletion Coefficient, p----0.45\\xa0Root Depth, m1.5>>>>1.5\\xa0Crop Coefficient, Kc0.3>>0.70.45\\xa0Yield Response Factor, Ky0.20.70.850.40.85\\xa0\\n\\nWater Requirements\\nWater RequirementsThe crop coefficient (kc) will vary with cultural practices. The kc value, relating the maximum water requirements (ETm) to the reference evapotranspiration (ETo), for clean cultivated conditions, infrequent irrigation and a dry soil surface most of the time is:JanFebMarAprMayJunJulAugSepOctNovDecMature grapevines grown in areas with killing frost; initial leaves early May, harvest mid-September; ground cover 40-50% at mid-season----.45-.5.65-.75.75-.9.8-.95.75-.9.65-.75--Mature grapevines in areas with light frost; initial leaves early April, harvest late August to early September; ground cover 30-35% at mid-season---.45-.5.55-.65.6-.75.6-.75.6-.75.6-.75.5-.65.35-.4-Mature grapevines grown in hot, dry areas and mild winter; initial leaves late February - early March, harvest late July; ground cover 30-35% at mid-season--.25.45.6-.65.7-.75.7-.75.65-.7.55.45.35-Total seasonal requirements vary between 500 and 1200 mm, depending mainly on climate and length of growing period.\\n\\nWater Supply And Crop Yield\\nThe relationships between relative yield decrease (1 - Ya/Ym) and relative evapotranspiration deficit for the total growing period are shown in the figure below.\\n\\n\\n\\nGrape is a perennial crop and can adjust to a certain extent to limited water supply by developing a deep root system. When soil water even over great soil depth becomes limited and overnight recovery from wilting does not occur, growth will diminish and eventually stop. Subsequently leaf and shoot colour change to a dark greyish-green, the shoot tips become dry, the leaves curl, the tendrils abscise and eventually the leaves die and fall.\\n\\nIn the subtropics and temperate climates, flowerbud formation generally occurs during the late summer or autumn and the buds open during the next season. A slight deficiency of water, together with high sunshine and temperatures, is considered to be most favourable to flower bud formation. A dry summer and a relatively low yield appears to be more advantageous to flower bud formation than a wet summer and a heavy yield.\\n\\nFor good fruit production in the same year and the following years, good vegetative growth during the first part of the growing period (vegetative period, 1) is important.Water deficit should not occur during this period of rapid lateral shoot growth. The soil water content should preferably be at field capacity at the end of the winter, by winter rain or by irrigation, to ensure adequate water supply during the first months of the growing period. Especially shoot elongation is very sensitive to water deficits. Adequately irrigated vines have significantly more prunings than those grown under water deficit conditions. If water stress occurs abruptly, the growth is checked and wilting and dieback occur; if water stress develops gradually the vine growth is adjusted by lessened shoot growth, smaller production and earlier ripening. However, vegetative growth should be low during fruit formation and should stop toward harvest to ensure good ripening of the fruit and maturing of the wood.\\n\\nPrior and during flowering (2), adequate water supply is necessary for flower development. Water deficits at this time retard flower development while severe water deficit reduces fruit set. Also the nutrition requirements of the grapevine are high during this period and the subsequent fruit enlargement period. Leaching of nutrients must be avoided in this period.\\n\\nYield formation (fruit enlargement, 3) depends on a steady, continuous water supply, but in this period the crop is less sensitive to water deficits than during the period of shoot growth (1). Water deficits during fruit enlargement reduce fruit size. Later irrigation does not result in undersized fruits becoming normal size. Water deficits prior to or just after veraison (start of ripening, fruits soften and change colour) affect fruit size more than deficits just before harvest.\\n\\nSevere water deficit causes shrivelling of the fruits at all stages of yield formation (3) and ripening (4) and is first observed in the immature fruits on any cluster. The shrivelling usually disappears after rewatering. Complete desiccation is confined to the smaller fruits (less than about 4 mm in diameter). When the crop is subjected to severe water deficits after v6raison, maturity is delayed while the fruits may not even reach full maturity. A slight water deficit during the ripening period (4) may hasten maturity, while juice concentration is increased.\\n\\nWater deficits throughout the growing season result in darker wine but may not affect the quality of the wine. Severe water deficit during yield formation (3) and ripening (4) results in the fruit having a dull colour. It also leads to sunburn but reduces the incidence of fruit rot. Severe deficits just after v6raison reduce the content of total soluble solids.\\n\\nAfter the fruit is mature and especially after harvest, the vines become adjusted to a limited water supply. Normally no further growth occurs, but leaves are retained and canes ripen even though soil water content is low. In hot, dry regions, water deficit after harvest will cause the leaves to fall; when weather becomes cool in autumn, new leaves can be formed without becoming mature. This will lead to poor production in the next year. Water supply after harvest must therefore be sufficient to maintain the healthy foliage and to prevent premature leaffall. However, too much water after harvest causes new shoot growth, which has the same detrimental effects as new leaf growth. The relation between relative yield decrease and relative evapotranspiration deficit is given for conditions when soil water stress occurs mainly in the second part of the total growing period, and water supply during early vegetative growth (1) and the flowering period (2) is adequate (Fig. 16). To maximize total production if water supply is limited the cultivated area may be extended and crop water requirements partially met, rather than meeting full crop water requirements on a limited area.\\n\\nWater Uptake\\nWater UptakeWhen root penetration is not obstructed, mature grapevines are deep rooted up to depths of 2 or 3 m, or more. In deep, coarse sand or gravelly soils, roots may be up to 4 to 8 m deep.The bulk of the roots are usually in the upper soil layer of 0.5 to 1.5 rn. Normally 100 percent of the water is extracted from the first 1 to 2 m soil depth (D = 1-2 m). During vegetative growth (1), flowering (2) and the early part of yield formation (early 3) maximum evapotranspiration will be affected at a soil water depletion (p) of about 0.35 to 0.45, under conditions when ETm is 5 to 6 mm/day. Later in the growing period the soil water can be depleted to a higher level, while toward and after harvest time a high soil water depletion is required.\\n\\nIrrigation Scheduling\\nIrrigation SchedulingWhen winter rainfall is insufficient to fill the full root zone to field capacity, irrigation should be applied before vegetative growth starts. Until the beginning of the veraison water must be applied when 35 to 45 percent of the total available soil water is depleted. Whether irrigation is necessary after veraison depends on the total available water over the root depth in relation to ETm. In shallow and light soils, irrigation will be necessary until harvest, but be applied at higher soil water depletion levels (soil water potential between 1 and 5 bars).\\n\\nIn deep, fine textured soils irrigation should be discontinued in time to achieve the desired soil water depletion level toward harvest time. In warm, dry climates or when the grapes are harvested early, a light irrigation may, however, be required to prevent the soil from becoming too dry (water potential not exceeding 5 to 10 bars).\\n\\nWhen sprinkler irrigation is practised, after veraison irrigation should not take place during humid periods in order to assure rapid drying of the leaves (8 to 12 hours), and to reduce foliar burn and the hazard of fruit rot.\\n\\nIrrigation Methods\\nIrrigation MethodsFurrow irrigation with 2 or 3 furrows between the rows is mostly used. Sprinkler irrigation becomes more common since it can also be used for spring frost protection where needed. Sprinkler is less advantageous when irrigation is also required during the ripening period because of the likely increase in bunch rot. In new vineyards and especially where irrigation water is scarce, drip irrigation is increasingly being introduced.\\n\\nYield\\nYieldSimilarly to other perennial crops, yield per vine varies considerably from year to year and from plant to plant. The maximum yield level depends on the variety and growing environment. Good commercial yields in the subtropics are in the range of 15 to 20 kg grapes per vine or 15 to 30 (or more) tons/ha (80 to 85 percent moisture). Yields in the tropics are in the range of 5 to 10 ton/ha. The water utilization efficiency for harvested yield (Ey) for fresh fruits containing about 80 percent moisture is 2 to 4 kg/m3 when grape is grown in the subtropics.\\n\\n',\n",
       "   'description': 'This section presents information on water relations and water management of grape and provides links to other sources of information.',\n",
       "   'link': 'https://www.fao.org/land-water/databases-and-software/crop-information/grape/es/',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Commodities detail | CODEXALIMENTARIUS FAO-WHO',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/fao-who-codexalimentarius/codex-texts/dbs/pestres/commodities-detail/en/?c_id=113',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Food loss analysis - Grapes value chain in Egypt',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/publications/card/en/c/CA5876EN/',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': '5. GRAPE PRODUCTION IN INDIA',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/4/x6897e/x6897e06.htm',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Analysis of food loss in the cucumber, zucchini and table grapes ...',\n",
       "   'content': '',\n",
       "   'description': '-',\n",
       "   'link': 'https://www.fao.org/family-farming/detail/en/c/1652753/',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Republic of Moldova',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/one-country-one-priority-product/fao-regional-knowledge-platform-on-ocop-in-europe-and-central-asia/republic-of-moldova/en',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Boosting knowledge for a better harvest | FAO Stories | Food and ...',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/fao-stories/article/en/c/1154395/',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Grape production system in Jowzan Valley | Globally Important ...',\n",
       "   'content': '',\n",
       "   'description': '-',\n",
       "   'link': 'https://www.fao.org/giahs/giahsaroundtheworld/designated-sites/asia-and-the-pacific/grape-production-system-in-jowzan-valley/en/',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': 'Food loss analysis for grapes value chains in Egypt',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/documents/card/fr/c/CB4676EN/',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'},\n",
       "  {'title': '9. GRAPE PRODUCTION IN THAILAND',\n",
       "   'content': '',\n",
       "   'description': '',\n",
       "   'link': 'https://www.fao.org/4/x6897E/x6897e0a.htm',\n",
       "   'query': 'Grapes',\n",
       "   'category': 'Agriculture'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapper = FAO_Scrapper()\n",
    "\n",
    "query = \"Grapes\"\n",
    "scrapper.get_query_data(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "class Investopedia_Scrapper:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://www.investopedia.com/search?\"\n",
    "        self.query = None\n",
    "\n",
    "    def get_query_data(self, query):\n",
    "        processed_query = query.replace(\" \", \"+\")\n",
    "\n",
    "        if not processed_query:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.query = processed_query\n",
    "\n",
    "        url = self.url + \"q=\" + processed_query\n",
    "\n",
    "        response = self.get_data(processed_query, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "\n",
    "    def get_data(self, query, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "        \n",
    "        query_data = soup.find('div', class_='comp search-results__results mntl-block')\n",
    "        if query_data:\n",
    "            cards = query_data.find_all(\n",
    "                'div', class_='comp search-results__list mntl-block')\n",
    "            for card in cards:\n",
    "                title = \"\"\n",
    "                desc = \"\"\n",
    "                date = \"\"\n",
    "                author = \"\"\n",
    "                author_link = \"\"\n",
    "                reviewer = \"\"\n",
    "                reviewer_link = \"\"\n",
    "                content = \"\"\n",
    "                link = \"\"\n",
    "                keypoints = \"\"\n",
    "                category = \"Finance\"\n",
    "\n",
    "                link_holder = card.find('a')\n",
    "                link = link_holder['href']\n",
    "                title_holder = link_holder.find('h3')\n",
    "                title = title_holder.text\n",
    "                desc_holder = card.find(\n",
    "                    'div', class_='comp search-results__description mntl-text-block')\n",
    "                desc = desc_holder.text\n",
    "\n",
    "                home_page = requests.get(link)\n",
    "                home_page.raise_for_status()\n",
    "                home_soup = BeautifulSoup(home_page.text, 'html.parser')\n",
    "\n",
    "                content_holder = home_soup.find(\n",
    "                    'div', class_='loc article-content')\n",
    "                if content_holder:\n",
    "                    content_holder = content_holder.find(\n",
    "                        'div', class_='comp article-body mntl-block')\n",
    "                    if content_holder:\n",
    "                        content_holder = content_holder.find(\n",
    "                            'div', class_='comp mntl-sc-page mntl-block article-body-content')\n",
    "                        if content_holder:\n",
    "                            paragraphs = content_holder.find_all('p')\n",
    "                            content = \"\"\n",
    "                            for p in paragraphs:\n",
    "                                content += p.text + \" \"\n",
    "                            keypoints = content_holder.find('div', class_='comp mntl-sc-key-points mntl-block')\n",
    "                            if keypoints:\n",
    "                                keypoints = keypoints.find(\n",
    "                                    'div', class_='comp mntl-sc-block mntl-sc-block-callout mntl-block theme-whatyouneedtoknow')\n",
    "                                if keypoints:\n",
    "                                    keypoints = keypoints.find(\n",
    "                                        'div', class_='comp mntl-sc-block-callout-body mntl-text-block')\n",
    "                                    if keypoints:\n",
    "                                        keypoints = keypoints.find('ul')\n",
    "                                        if keypoints:\n",
    "                                            keypoints = keypoints.find_all('li')\n",
    "                                            keys = \"\"\n",
    "                                            for key in keypoints:\n",
    "                                                keys += key.text + \" \"\n",
    "                                            keypoints = keys\n",
    "\n",
    "                header_holder = home_soup.find(\n",
    "                    'header', class_='loc article-pre-content')\n",
    "                if header_holder:\n",
    "                    header_holder = header_holder.find(\n",
    "                        'header', class_='comp article-header mntl-block right-rail__offset js-toc-appear')\n",
    "                    if header_holder:\n",
    "                        meta_holder = header_holder.find('div', class_='comp article-meta mntl-block')\n",
    "                        if meta_holder:\n",
    "                            meta_holder = meta_holder.find(\n",
    "                                'div', class_='comp finance-bylines mntl-bylines')\n",
    "                            if meta_holder:\n",
    "                                author_and_date = meta_holder.find('div', class_='comp mntl-bylines__group mntl-block mntl-bylines__group--author')\n",
    "                                if author_and_date:\n",
    "                                    author_holder = author_and_date.find('div', class_='comp mntl-bylines__item mntl-attribution__item mntl-attribution__item--has-date')\n",
    "                                    if author_holder:\n",
    "                                        author_holder = author_holder.find(\n",
    "                                            'div', class_='mntl-dynamic-tooltip--trigger')\n",
    "                                        if author_holder:\n",
    "                                            author_holder = author_holder.find('a')\n",
    "                                            author = author_holder.text\n",
    "                                            author_link = author_holder['href']\n",
    "                                    date_holder = author_and_date.find(\n",
    "                                        'div', class_='mntl-attribution__item-date')\n",
    "                                    if date_holder:\n",
    "                                        date = date_holder.text\n",
    "                                reviewer_holder = meta_holder.find(\n",
    "                                    'div', class_='comp mntl-bylines__group mntl-block mntl-bylines__group--finance_reviewer')\n",
    "                                if reviewer_holder:\n",
    "                                    reviewer_holder = reviewer_holder.find(\n",
    "                                        'div', class_='comp mntl-bylines__item mntl-attribution__item')\n",
    "                                    if reviewer_holder:\n",
    "                                        reviewer_holder = reviewer_holder.find(\n",
    "                                            'div', class_='mntl-dynamic-tooltip--trigger')\n",
    "                                        if reviewer_holder:\n",
    "                                            reviewer_holder = reviewer_holder.find('a')\n",
    "                                            reviewer = reviewer_holder.text\n",
    "                                            reviewer_link = reviewer_holder['href']\n",
    "\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"description\": desc,\n",
    "                    \"date\": date,\n",
    "                    \"author\": author,\n",
    "                    \"author_link\": author_link,\n",
    "                    \"reviewer\": reviewer,\n",
    "                    \"reviewer_link\": reviewer_link,\n",
    "                    \"content\": content,\n",
    "                    \"link\": link,\n",
    "                    \"keypoints\": keypoints,\n",
    "                    \"query\": query,\n",
    "                    \"category\": category\n",
    "                })\n",
    "\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = [\n",
    "                    'title', 'description', 'date', 'author', 'author_link', 'reviewer', 'reviewer_link', 'content', 'link', 'keypoints', 'query', 'category']\n",
    "                if os.path.isfile('Investopedia.csv') and os.path.getsize('Investopedia.csv') > 0:\n",
    "                    df.to_csv('Investopedia.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('Investopedia.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Response': {'Error': '406 Client Error: Not Acceptable for url: https://www.investopedia.com/search?q=Mukesh+Ambani'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapper = Investopedia_Scrapper()\n",
    "\n",
    "query = \"Mukesh Ambani\"\n",
    "scrapper.get_query_data(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
