{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_name = input(\"What is the name of the player you want to search for? \")\n",
    "platform = input(\"What platform is the player on? \")\n",
    "type = input(\"What is the type of the player? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_player_name = player_name.replace(\" \", \"+\")\n",
    "processed_platform = platform.lower()\n",
    "processed_type = type.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "query = f\"https://www.bcci.tv/search?platform={processed_platform}&type={processed_type}&term={processed_player_name}&content_type=all\"\n",
    "\n",
    "if not processed_player_name or not processed_platform or not processed_type:\n",
    "    print(\"Invalid input\")\n",
    "    exit()\n",
    "else:\n",
    "    try:\n",
    "        response = requests.get(query)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    data = []\n",
    "\n",
    "    player_data = soup.find('div', class_='lv pc video-section-append-video-here')\n",
    "    if player_data:\n",
    "        player_card = player_data.find_all(\n",
    "            'div', class_='slick-card m-0 lv-bg hoverVideoPlayNow')\n",
    "        for card in player_card:\n",
    "            header_content = card.find('div', class_='bottom')\n",
    "            title_holder = None\n",
    "            title = \"\"\n",
    "            date = \"\"\n",
    "            views = \"\"\n",
    "            if header_content.find('div', class_='text-detail br-b'):\n",
    "                title_holder = header_content.find('div', class_='text-detail br-b')\n",
    "                date_holder = header_content.find('div', class_='text-detail br-b')\n",
    "                date =  date_holder.find('span').text\n",
    "                views_holder = header_content.find(\n",
    "                    'div', class_='tour-overlay-details')\n",
    "                list = views_holder.find('ul')\n",
    "                views = list.find_all('li')[0]\n",
    "                views = views.find('span', class_=\"me-3\").text\n",
    "                views = views.replace(\"&nbsp;\", \"\").replace(\n",
    "                    \"views\", \"\").replace(\"\\n\", \"\").replace(\"\\xa0\", \"\").strip()\n",
    "                if \"k\" in views:\n",
    "                    views = views.replace(\"k\", \"\")\n",
    "                    views = float(views) * 1000\n",
    "                elif \"m\" in views:\n",
    "                    views = views.replace(\"m\", \"\")\n",
    "                    views = float(views) * 1000000\n",
    "            elif header_content.find('div', class_='text-detail pb-0'):\n",
    "                title_holder = header_content.find('div', class_='text-detail pb-0')\n",
    "                date_holder = header_content.find(\n",
    "                    'div', class_='tour-overlay-details')\n",
    "                ul = date_holder.find('ul')\n",
    "                date_ = ul.find_all('li')[0]\n",
    "                date = date_.find('span').text\n",
    "                views = \"-\"\n",
    "            if title_holder:\n",
    "                title = title_holder.find('p').text\n",
    "\n",
    "            data.append({\n",
    "                \"title\": title,\n",
    "                \"date\": date,\n",
    "                \"views\": views,\n",
    "                \"platform\": processed_platform,\n",
    "                \"type\": processed_type,\n",
    "                \"player_name\": player_name,\n",
    "                \"sport\": \"Cricket\"\n",
    "            })\n",
    "        if data:\n",
    "            df = pd.DataFrame(data)\n",
    "            header = ['title', 'date', 'views', 'platform', 'type', 'player_name']\n",
    "            if os.path.isfile('Sports.csv') and os.path.getsize('Sports.csv') > 0:\n",
    "                df.to_csv('Sports.csv', mode='a', header=False, index=False)\n",
    "            else:\n",
    "                df.to_csv('Sports.csv', mode='a', header=header, index=False)\n",
    "    else:\n",
    "        print(\"Player not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ICC_Scrapper:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://www.icc-cricket.com/search?\"\n",
    "        self.player_name = None\n",
    "\n",
    "    def get_player_data(self, player_name):\n",
    "        processed_player_name = player_name.replace(\" \", \"%20\")\n",
    "\n",
    "        if not processed_player_name:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.player_name = processed_player_name\n",
    "\n",
    "        url = self.url + \"q=\" + self.player_name\n",
    "\n",
    "        response = self.get_data(processed_player_name, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "\n",
    "    def get_data(self, player_name, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        player_data = soup.find(\n",
    "            'div', class_='my-4 grid grid-cols-1 lg:grid-cols-4 gap-6 lg:gap-x-6 lg:gap-y-10')\n",
    "        if player_data:\n",
    "            cards = player_data.find_all(\n",
    "                'div', class_='h-[541px] relative rounded-lg lg:rounded-[14px] overflow-hidden')\n",
    "            for card in cards:\n",
    "                title = \"\"\n",
    "                date = \"\"\n",
    "                content = \"\"\n",
    "                image_url = \"\"\n",
    "                link = \"\"\n",
    "                link_holder = card.find('a')\n",
    "                link = link_holder['href']\n",
    "                image_holder = link_holder.find_all(\n",
    "                    'div')[0]\n",
    "                image_holder = image_holder.find('picture')\n",
    "                image_holder = image_holder.find('img')\n",
    "                image_url = image_holder['src']\n",
    "                divs = link_holder.find_all('div')\n",
    "                if len(divs) > 1:\n",
    "                    content_holder = divs[1]\n",
    "                    content_holder = content_holder.find('div')\n",
    "                    title_holder = content_holder.find_all('div')[1] if len(\n",
    "                        content_holder.find_all('div')) > 1 else None\n",
    "                    if title_holder:\n",
    "                        title = title_holder.text\n",
    "                    content_holder = content_holder.find(\n",
    "                        'div', class_='text-sm font-bold text-white leading-[1.2] lg:text-lg lg:leading-[1.4] lg:-tracking-[0.72px]')\n",
    "                    if content_holder:\n",
    "                        content = content_holder.text\n",
    "                    date_holder = content_holder.find('time')\n",
    "                    date = date_holder.text if date_holder else \"\"\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                temp_player_name = player_name.replace(\"%20\", \" \")\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"date\": date,\n",
    "                    \"content\": content,\n",
    "                    \"player_name\": temp_player_name,\n",
    "                    \"image_url\": image_url,\n",
    "                    \"link\": link,\n",
    "                    \"sport\": \"Cricket\"\n",
    "                })\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'date', 'content',\n",
    "                          'player_name', 'image_url', 'link', 'sport']\n",
    "                if os.path.isfile('ICC.csv') and os.path.getsize('ICC.csv') > 0:\n",
    "                    df.to_csv('ICC.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('ICC.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = ICC_Scrapper()\n",
    "\n",
    "# player_name = \"MS Dhoni\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "player_name = \"Sachin Tendulkar\"\n",
    "scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Sourav Ganguly\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Ravindra Jadeja\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Jasprit Bumrah\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Mithali Raj\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Smriti Mandhana\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Jhulan Goswami\"\n",
    "# scrapper.get_player_data(player_name)\n",
    "\n",
    "# player_name = \"Harmanpreet Kaur\"\n",
    "# scrapper.get_player_data(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class FIFA_Scrapper:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://www.fifa.com/en/search?\"\n",
    "        self.player_name = None\n",
    "\n",
    "    def get_player_data(self, player_name):\n",
    "        processed_player_name = player_name.replace(\" \", \"%20\")\n",
    "\n",
    "        if not processed_player_name:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.player_name = processed_player_name\n",
    "\n",
    "        url = self.url + \"q=\" + self.player_name\n",
    "\n",
    "        response = self.get_data(processed_player_name, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "\n",
    "    def get_data(self, player_name, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        player_data = soup.find(\n",
    "            'div', class_='search-results-page_searchResults__pKRI-')\n",
    "        if player_data:\n",
    "            title = \"\"\n",
    "            date = \"\"\n",
    "            content = \"\"\n",
    "            image_url = \"\"\n",
    "            link = \"\"\n",
    "            player_name = \"\"\n",
    "            sport = \"Football\"\n",
    "            cards = player_data.find_all('a')\n",
    "            for card in cards:\n",
    "                link = card['href']\n",
    "                date_holder = card.find(\n",
    "                    'div', class_='search-result-card_details__+1JIM')\n",
    "                date = date_holder.find('span')[1].text\n",
    "                image_holder = card.find(\n",
    "                    'div', class_='search-result-card_imageContainer__NgxbS')\n",
    "                image_holder = image_holder.find(\n",
    "                    'div', class_='image_imgContainer__nDjya')\n",
    "                image_holder = image_holder.find('img')\n",
    "                image_url = image_holder['src']\n",
    "                content_holder = card.find(\n",
    "                    'div', class_='search-result-card_textContainer__82BrL')\n",
    "                title_holder = content_holder.find(\n",
    "                    'div', class_='search-result-card_title__CTmi4')\n",
    "                title = title_holder.text\n",
    "                content_holder = content_holder.find(\n",
    "                    'div', class_='search-result-card_description__KiKIZ search-result-card_smallCardDescription__InIop')\n",
    "                content = content_holder.text\n",
    "                temp_player_name = player_name.replace(\"%20\", \" \")\n",
    "                data.append({\n",
    "                    \"title\": title,\n",
    "                    \"date\": date,\n",
    "                    \"content\": content,\n",
    "                    \"player_name\": temp_player_name,\n",
    "                    \"image_url\": image_url,\n",
    "                    \"link\": link,\n",
    "                    \"sport\": sport\n",
    "                })\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'date', 'content',\n",
    "                          'player_name', 'image_url', 'link', 'sport']\n",
    "                if os.path.isfile('FIFA.csv') and os.path.getsize('FIFA.csv') > 0:\n",
    "                    df.to_csv('FIFA.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('FIFA.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = FIFA_Scrapper()\n",
    "\n",
    "player_name = \"Lionel Messi\"\n",
    "scrapper.get_player_data(player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "class ICAR_Scrapper:\n",
    "    def __init__ (self):\n",
    "        self.url = \"https://www.icar.org.in/search/node?keys=\"\n",
    "        self.query = None\n",
    "\n",
    "    def get_query_data(self, query):\n",
    "        processed_query = query.replace(\" \", \"%20\")\n",
    "\n",
    "        if not processed_query:\n",
    "            return {\"Error\": \"Invalid input\"}\n",
    "\n",
    "        self.query = processed_query\n",
    "\n",
    "        url = self.url + processed_query\n",
    "\n",
    "        response = self.get_data(processed_query, url)\n",
    "\n",
    "        if response:\n",
    "            return {\"Response\": response}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "        \n",
    "    def get_data(self, query, url):\n",
    "        try:\n",
    "            response = requests.get(url, verify=False)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            return {\"Error\": str(e)}\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        query_data = soup.find(\n",
    "            'ol', class_='search-results node_search-results')\n",
    "        if query_data:\n",
    "            title = \"\"\n",
    "            date = \"\"\n",
    "            content = \"\"\n",
    "            link = \"\"\n",
    "            place = \"\"\n",
    "\n",
    "            li_tags = query_data.find_all('li')\n",
    "            if li_tags:\n",
    "                for li in li_tags:\n",
    "                    title_holder = li.find('h3')\n",
    "                    title_holder = title_holder.find('a')\n",
    "                    link = title_holder['href']\n",
    "                    title = title_holder.text\n",
    "\n",
    "                    home_page = requests.get(link, verify=False)\n",
    "                    home_page.raise_for_status()\n",
    "                    home_soup = BeautifulSoup(home_page.text, 'html.parser')\n",
    "\n",
    "                    content_holder = home_soup.find(\n",
    "                        'div', class_='node__content clearfix')\n",
    "                    if content_holder:\n",
    "                        content_holder = content_holder.find(\n",
    "                            'div', class_='clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item')\n",
    "                    \n",
    "                    if content_holder:\n",
    "                        paragraphs = content_holder.find_all('p')\n",
    "                        if paragraphs[0].find('em'):\n",
    "                            date_place = paragraphs[0].find('em')\n",
    "                            date_place = date_place.text   \n",
    "                            date_place = date_place.split(',')\n",
    "                            if len(date_place) == 2:\n",
    "                                if any(char.isdigit() for char in date_place[0]):\n",
    "                                    date = date_place[0]\n",
    "                                    place = date_place[1]\n",
    "                                else:\n",
    "                                    date = date_place[1]\n",
    "                                    place = date_place[0]\n",
    "                            elif len(date_place) == 3:\n",
    "                                date = date_place[0] + ', ' + date_place[1]\n",
    "                                place = date_place[2]\n",
    "                            content = \"\"\n",
    "                            for i in range(1, len(paragraphs)):\n",
    "                                content += paragraphs[i].text + \" \"\n",
    "                        else:\n",
    "                            date = \"-\"\n",
    "                            place = \"-\"\n",
    "                            content = \"\"\n",
    "                            for i in range(0, len(paragraphs)):\n",
    "                                content += paragraphs[i].text + \" \"\n",
    "\n",
    "                    data.append({\n",
    "                        \"title\": title,\n",
    "                        \"date\": date,\n",
    "                        \"content\": content,\n",
    "                        \"link\": link,\n",
    "                        \"place\": place,\n",
    "                        \"query\": query,\n",
    "                        \"category\": \"Agriculture\"\n",
    "                    })\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                header = ['title', 'date', 'content', 'link', 'place', 'query', 'category']\n",
    "                if os.path.isfile('ICAR.csv') and os.path.getsize('ICAR.csv') > 0:\n",
    "                    df.to_csv('ICAR.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('ICAR.csv', mode='a', header=header, index=False)\n",
    "                return data\n",
    "            else:\n",
    "                return {\"Error\": \"No data found\"}\n",
    "        else:\n",
    "            return {\"Error\": \"No data found\"}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.icar.org.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Response': [{'title': 'Webinar on “Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”',\n",
       "   'date': '20th\\xa0August,  2020',\n",
       "   'content': 'The ICAR-National Research Centre on Grapes, Pune, Maharashtra organized a Webinar on\\xa0“Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”\\xa0today. In his address, Dr. Anand Kumar Singh, Deputy Director General (Horticultural Science), ICAR emphasized on the importance of following the good agricultural practices for pesticide applications in grape cultivation. Dr. Singh also urged the participants for providing the technologies and recommendations for effective management of pesticide residues in grapes. Shri Devendra Prasad, DGM, APEDA along with the members of Maharashtra State Grape Growers’ Association (MRDBS) also virtually participated in the Webinar. Earlier, in his welcome address, Dr. R.G. Somkuwar, Director, ICAR-NRC on Grapes, Pune, Maharashthra briefed about the current grape season. He accentuated on the updation of the list\\xa0list of agrochemicals in Annexure - 5 of the Residue Monitoring Plan Document based on the new CIB&RC-label claims for grapes by the Institute every year. Dr. Kaushik Banerjee, Incharge, NRL outlined the agenda and briefed about the structure of Annexure - 5 as the central theme of the pesticide residue control in the food safety traceability system, viz., Grapenet of APEDA. A total of 238 participants including the grape growers from the various locations of Maharashtra and Karnataka states virtually participated in the Webinar. (Source: ICAR-National Research Centre on Grapes, Pune, Maharashtra) ',\n",
       "   'link': 'https://www.icar.org.in/node/1206',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Webinar on “Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”',\n",
       "   'date': '20th\\xa0August,  2020',\n",
       "   'content': 'The ICAR-National Research Centre on Grapes, Pune, Maharashtra organized a Webinar on\\xa0“Export of Grapes in 2021: Instructions for uses of authorized agrochemicals as per Annexure - 5 of Residue Monitoring Plan”\\xa0today. In his address, Dr. Anand Kumar Singh, Deputy Director General (Horticultural Science), ICAR emphasized on the importance of following the good agricultural practices for pesticide applications in grape cultivation. Dr. Singh also urged the participants for providing the technologies and recommendations for effective management of pesticide residues in grapes. Shri Devendra Prasad, DGM, APEDA along with the members of Maharashtra State Grape Growers’ Association (MRDBS) also virtually participated in the Webinar. Earlier, in his welcome address, Dr. R.G. Somkuwar, Director, ICAR-NRC on Grapes, Pune, Maharashthra briefed about the current grape season. He accentuated on the updation of the list\\xa0list of agrochemicals in Annexure - 5 of the Residue Monitoring Plan Document based on the new CIB&RC-label claims for grapes by the Institute every year. Dr. Kaushik Banerjee, Incharge, NRL outlined the agenda and briefed about the structure of Annexure - 5 as the central theme of the pesticide residue control in the food safety traceability system, viz., Grapenet of APEDA. A total of 238 participants including the grape growers from the various locations of Maharashtra and Karnataka states virtually participated in the Webinar. (Source: ICAR-National Research Centre on Grapes, Pune, Maharashtra) ',\n",
       "   'link': 'https://www.icar.org.in/node/12586',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': '20th Foundation Day of NRC for Grapes',\n",
       "   'date': ' 18th\\xa0January 2016.',\n",
       "   'content': 'Two progressive farmers Mr. Subash Arve (President MRDBS) and Mr Shivajirao Baste were felicitated for collaborating with NRC for Grapes in field of demonstration of technologies and varieties developed by the NRC for Grapes at the 20 Foundation Day of National Research Centre for Grapes. Mr Subash Arve delivered a\\xa0 technical talk on ‘ Current status of dry grape industry in India and its future’. \\xa0 The importance of keeping alive the interest of rural youth in agriculture for holistic development of the country and in tune with the market and consumer demands was emphasized by the chief guest Mr Dnyaneshwar Phadtare (Retd. Joint Commissioner of Vigilance, Maharashtra). Dr P. S. Minhas (Director, NIASM, Baramati) focused on the need to strengthen the collaborative work between NIASM and NRCG in the management of edaphic stress in grapes. Dr Jai Gopal (Director,DOGR) highlighted importance of breeding for development of grape varieties with desired traits. Dr K. V. Prasad (Director, DFR) spoke on the scope of incorporation of natural colors and flavors from ornamental crops in grape juice. The wall magazine,\\xa0‘Angoori’\\xa0 of NRC for Grapes brought out a special issue depicting photographs and memoirs of the establishment of the NRC for Grapes. (Source: ICAR-NRC on Grapes,\\xa0Pune) ',\n",
       "   'link': 'https://www.icar.org.in/node/4876',\n",
       "   'place': 'Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'NRC for Grapes, celebrates 120th Birth Anniversary of Dr. G.S. Cheema',\n",
       "   'date': 'August 2,  2014',\n",
       "   'content': '120th Birth Anniversary of Dr. G.S. Cheema was celebrated in National Research Centre for Grapes (NRCG), Pune.  Dr. S.D. Sawant, Director addressed the staff and highlighted Dr. Cheema’s contributions to horticulture especially in developing varieties namely Sardar Guava, Ganesh Pomegranate and Cheema Sahebi grapes. Dr. G.S. Cheema, an eminent horticulturist, who had been commonly referred to as the Father of Indian Horticulture. \\xa0 He also informed that the Centre has named its laboratory-cum-administrative building as Dr. G.S. Cheema Bhawan to recognize his contributions to grapes. (Source: NRC for Grapes, Pune) ',\n",
       "   'link': 'https://www.icar.org.in/node/9714',\n",
       "   'place': ' Pune ',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'ICAR-NRC for Grapes, organises National Conference on Generative AI',\n",
       "   'date': '11th-12th September 2023',\n",
       "   'content': \"ICAR-National Research Centre for Grapes, Pune, in collaboration with National Academy of Agricultural Sciences and Society for Advancement of Viticulture and Enology, held a two-day National Conference on “Generative AI in Practice for Empowering Agricultural Research Productivity” by virtual mode. \\xa0\\xa0 The Chief Guest of both Inauguration and Valedictory sessions, Dr. S. D. Sawant, former Vice Chancellor, Dr. Balasaheb Sawant Konkan Krishi Vidyapeeth, Dapoli, Ratnagiri emphasised on Generative AI's potential as a revolutionary tool in agricultural research. He mentioned that as we ventured into this new realm for reaping benefits, the emphasis remained on ethical deployment and responsible use. Dr. C.N. Ravishankar, Director, ICAR-CIFE, Mumbai, briefed them about potential applications of Generative AI in the aquaculture sector. Dr. Kaushik Banerjee, Director, ICAR-National Research Centre for Grapes, Pune and Convener, NAAS, emphasised on importance of learning and adopting generative AI for agricultural researchers for remaining relevant with fast changing technology. He also suggested to maintain balance with human intelligence. The online event drew 130 researchers from across the country over the course of two days. 30 lectures and six keynote addresses illuminated the broad potential of generative AI for the productivity of agricultural research. (Source: ICAR-National Research Centre for Grapes, Pune) \",\n",
       "   'link': 'https://www.icar.org.in/icar-nrc-grapes-organises-national-conference-generative-ai',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'National Research Centres',\n",
       "   'date': '-',\n",
       "   'content': 'Mahatma Gandhi Integrated Farming Research Institute ,Motihari ',\n",
       "   'link': 'https://www.icar.org.in/national-research-centres',\n",
       "   'place': '-',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Meeting of the Agmark Committee',\n",
       "   'date': '20th November 2023',\n",
       "   'content': 'ICAR-National Research Centre for Grapes, Pune hosted a meeting of the Agmark Committee Today, under the co-chairmanship of Dr. Kaushik Banerjee, Director, ICAR-NRCG, Pune and Shri. B.K. Tiwari, I/c Jt. AMA-DMI Faridabad.  The meeting was attended by Dr. Ashish Mukharjee, Director of Laboratories, Dr. Vijay Kumar Doharey Dy. Managing Director, National Horticulture Board, Dr. B.K. Joshi, Dy. AMA-RO, Mumbai, officials from DMI, APEDA, and the State Department of Agriculture, and representatives of grape growers and exporters. The agenda of the meeting was to discuss the quality parameters under a schedule of Grapes of Fruits and Vegetables, Grading and Marking Rules, 2004. To certify the early harvest grapes for export, it was decided to revise the sugar: acid ratio from the existing value of 20:1 to 18:1. This was unanimously accepted by all the stakeholders’ representatives, including Maharashtra State Grape Growers Association and the Grape Exporters Association of India. All the attendees felt that this change in the Agmark standard will substantially increase the export of grapes, especially in the early harvest season of January–February, when Achieving a sugar:acid ratio of 20:1 often appears challenging. (Source: ICAR-National Research Centre for Grapes, Pune) ',\n",
       "   'link': 'https://www.icar.org.in/meeting-agmark-committee',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Vision 2050',\n",
       "   'date': '-',\n",
       "   'content': 'Deemed Universities Institutions National Research Centres National Bureaux Directorates/Project Directorates ',\n",
       "   'link': 'https://www.icar.org.in/vision-2050',\n",
       "   'place': '-',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'Agripreneurship Sensitization Programme',\n",
       "   'date': '5th March 2024',\n",
       "   'content': 'ICAR-National Research Centre for Grapes, Pune, ABI Draksha Centre, Pune organised an ‘Agripreneurship Sensitization Programme’ today for the students working under various projects of the institute. \\xa0\\xa0 Dr. Kaushik Banerjee, Director, ICAR-NRC for Grapes, highlighted the importance of science-based entrepreneurship developments in his address. He invited young minds to bring more and more innovations to enrich the agriculture-based business domain involving fresh grapes and processed products. A presentation on available opportunities and technologies developed by this research centre was also delivered during the programme. The programme was attended by more than 50 students. (Source: ICAR-National Research Centre for Grapes, Pune) ',\n",
       "   'link': 'https://www.icar.org.in/agripreneurship-sensitization-programme',\n",
       "   'place': ' Pune',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'},\n",
       "  {'title': 'ICAR Institutions, Deemed Universities, National Research Centres, National Bureaux, Directorate/Project Directorates & Agricultural Technology Application Research Institutes',\n",
       "   'date': '-',\n",
       "   'content': 'Mahatma Gandhi Integrated Farming Research Institute ,Motihari ',\n",
       "   'link': 'https://www.icar.org.in/institutes',\n",
       "   'place': '-',\n",
       "   'query': 'Grapes',\n",
       "   'sport': 'Agriculture'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper = ICAR_Scrapper()\n",
    "\n",
    "query = \"Grapes\"\n",
    "scraper.get_query_data(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
